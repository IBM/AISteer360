{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b03499",
   "metadata": {},
   "source": [
    "# Running TRL methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85443d1e",
   "metadata": {},
   "source": [
    "The toolkit implements some of the [TRL](https://github.com/huggingface/trl) methods via a `StructuralControl` wrapper. This guide shows how to run several methods:\n",
    "\n",
    "- SFT (supervised fine-tuning)\n",
    "- DPO (direct preference optimization)\n",
    "- APO (anchored preference optimization).\n",
    "- SPPO (self-play preference optimization)\n",
    "\n",
    "Note that while [SPPO](https://github.com/uclaml/SPPO) is not a part of TRL, it follows many of the similar abstractions so we include it as part of our TRL wrapper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e084a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992fdfa5",
   "metadata": {},
   "source": [
    "If running this from a Google Colab notebook, please uncomment the following cell to install the toolkit. The following block is not necessary if running this notebook from a virtual environment where the package has already been installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c314665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/IBM/AISteer360.git\n",
    "# %cd AISteer360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd683f7c",
   "metadata": {},
   "source": [
    "The following authentication steps may be necessary to access any gated models (after being granted access by Hugging Face). Uncomment the following if you need to log in to the Hugging Face Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install ipywidgets\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "\n",
    "# load_dotenv()\n",
    "# token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "# from huggingface_hub import login\n",
    "# login(token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4089bf8",
   "metadata": {},
   "source": [
    "Next, we import the `SteeringPipeline` class (used throughout) and specify the base model, in this case a small Qwen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0c79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import PeftType\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from aisteer360.algorithms.core.steering_pipeline import SteeringPipeline\n",
    "\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d663317c",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd798d2",
   "metadata": {},
   "source": [
    "The controls throughout this notebook are trained using a common dataset, `ultrafeedback_binarized`, since it contains preference data for each prompt (which is necessary for DPO-based controls). We load each of the splits below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d30c35fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61135,\n",
       " dict_keys(['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected']))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train = load_dataset(\"HuggingFaceH4/ultrafeedback_binarized\", split=\"train_prefs\")\n",
    "raw_test  = load_dataset(\"HuggingFaceH4/ultrafeedback_binarized\", split=\"test_prefs\")\n",
    "len(raw_train), raw_train[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77232ea0",
   "metadata": {},
   "source": [
    "Different trainers expect different data formats (i.e., tensor layouts) and thus we define two helper functions, one for SFT and one for DPO, to process the data in a way that is amenable to each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed94077a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sft_preprocess(example, tokenizer, max_length=1024):\n",
    "    text = f\"Question: {example['prompt']}\\n\\nAnswer: {example['chosen']}\"\n",
    "    encoding = tokenizer(text, truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    labels = [\n",
    "        token_id if mask == 1 else -100. # label pads as -100 so they don't contribute to loss\n",
    "        for token_id, mask in zip(encoding[\"input_ids\"], encoding[\"attention_mask\"])\n",
    "    ]\n",
    "    encoding[\"labels\"] = labels\n",
    "    return encoding\n",
    "\n",
    "def dpo_filter(example, max_prompt_chars=4000):\n",
    "    prompt = example[\"prompt\"]\n",
    "    if len(prompt) > max_prompt_chars:\n",
    "        prompt = prompt[:max_prompt_chars]\n",
    "    return {\"prompt\": prompt, \"chosen\": example[\"chosen\"], \"rejected\": example[\"rejected\"]}\n",
    "\n",
    "\n",
    "subset_size = 500\n",
    "\n",
    "sft_train = raw_train.select(range(subset_size)).map(\n",
    "    lambda example: sft_preprocess(example, tokenizer, max_length=1024),\n",
    "    remove_columns=raw_train.column_names\n",
    ")\n",
    "\n",
    "dpo_train = raw_train.select(range(subset_size)).map(dpo_filter, remove_columns=[])\n",
    "dpo_train[0].keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e1702",
   "metadata": {},
   "source": [
    "## SFT control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7c8de",
   "metadata": {},
   "source": [
    "We now show how to fine-tune with SFT using LoRA. We also merge the trained adapter back into the model (using the argument `merge_lora_after_train`). Note the argument `use_peft=True` to indicate that we are not running a full fine-tune (the example near the end of this notebook will illustrate a full fine-tuning run). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c89a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisteer360.algorithms.structural_control.wrappers.trl.sfttrainer.control import SFT\n",
    "\n",
    "\n",
    "sft = SFT(\n",
    "    # control loads model/tokenizer\n",
    "    base_model_name_or_path=MODEL_NAME,\n",
    "    tokenizer_name_or_path=MODEL_NAME,\n",
    "\n",
    "    # data\n",
    "    train_dataset=sft_train,\n",
    "    eval_dataset=None, \n",
    "    # data_collator=None  # optional; if omitted and you provided labels, you're fine\n",
    "\n",
    "    # TRL / Trainer config (forwarded into SFTConfig)\n",
    "    output_dir=\"./tmp/sft_lora\",\n",
    "    max_seq_length=1024,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-5,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    "\n",
    "    # PEFT (LoRA)\n",
    "    use_peft=True,\n",
    "    peft_type=PeftType.LORA,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    adapter_name=\"sft\",\n",
    "\n",
    "    # optionally merge LoRA into base weights after training\n",
    "    merge_lora_after_train=True,\n",
    "    merged_output_dir=\"./tmp/sft_lora_merged\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e64fd",
   "metadata": {},
   "source": [
    "We create a steering pipeline using the above control, with `lazy_init=True` since the structural control (`sft`) returns a model. The pipeline is then steered which invokes the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb6f6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 01:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.500100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.096400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sft_pipeline = SteeringPipeline(\n",
    "    lazy_init=True,\n",
    "    controls=[sft],\n",
    ")\n",
    "sft_pipeline.steer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a256987",
   "metadata": {},
   "source": [
    "The above SFT-trained pipeline is now ready for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b19d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' The sky looks blue because of the scattering of light by tiny dust particles in the atmosphere. These particles are small and light, so they scatter the light that hits them, causing it to bend around them and spread out into a colorless, milky cloud-like appearance known as the \"blue\" part of the sky.']\n"
     ]
    }
   ],
   "source": [
    "prompt_text = \"Question: What makes the sky look blue?\\n\\nAnswer:\"\n",
    "encoded = tokenizer(prompt_text, return_tensors=\"pt\")\n",
    "text = sft_pipeline.generate_text(\n",
    "    input_ids=encoded[\"input_ids\"],\n",
    "    attention_mask=encoded[\"attention_mask\"],\n",
    "    max_new_tokens=64\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d17982",
   "metadata": {},
   "source": [
    "## DPO control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecba008",
   "metadata": {},
   "source": [
    "DPO is instantiated in a similar fashion with the primary differences being that the training data is now triples (`prompt`, `chosen`, `rejected`), the trainer must keep a reference policy alongside the trainable policy, and the loss is a pair-wise KL-reg. contrastive objective rather than the token-level cross entropy loss in SFT. \n",
    "\n",
    "Note: By default, the trainer clones the base weights and freezes them. When LoRA is enabled, the wrapper automatically passes `ref_model=None`, letting TRL re-create a frozen reference that shares the same LoRA adapters. If you are full fine-tuning you can still supply your own `ref_model` via `pipeline.steer(ref_model=my_frozen_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisteer360.algorithms.structural_control.wrappers.trl.dpotrainer.control import DPO\n",
    "\n",
    "\n",
    "dpo = DPO(\n",
    "    base_model_name_or_path=MODEL_NAME,\n",
    "    tokenizer_name_or_path=MODEL_NAME,\n",
    "\n",
    "    train_dataset=dpo_train,\n",
    "\n",
    "    # DPO / TRL config (forwarded into DPOConfig)\n",
    "    output_dir=\"./tmp/dpo_lora\",\n",
    "    per_device_train_batch_size=2,  # often smaller than SFT\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=1e-6,\n",
    "    beta=0.1,\n",
    "    loss_type=\"sigmoid\",  # baseline DPO loss\n",
    "    max_prompt_length=512,\n",
    "    max_length=1024,\n",
    "    precompute_ref_log_probs=True,  # forwarded if supported by your TRL version\n",
    "    disable_dropout=True,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=123,\n",
    "\n",
    "    # LoRA\n",
    "    use_peft=True,\n",
    "    peft_type=PeftType.LORA,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    adapter_name=\"dpo\",\n",
    "\n",
    "    merge_lora_after_train=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e56422",
   "metadata": {},
   "source": [
    "As before, we create the pipeline using the control, steer the pipeline, and run inference on the steered pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5a902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
      "Train dataset reference log probs:  55%|███████████████████████████████████████████████████████████████████████████                                                              | 137/250 [01:11<00:58,  1.95it/s]"
     ]
    }
   ],
   "source": [
    "dpo_pipeline = SteeringPipeline(\n",
    "    lazy_init=True, \n",
    "    controls=[dpo]\n",
    ")\n",
    "dpo_pipeline.steer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e91b6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Yes, it is always helpful to be blunt with feedback. Blunt feedback can help you identify areas of improvement and provide a clear path for change. It also helps to build trust between the person being evaluated and the person giving the feedback.\\n\\nFor example, if someone gives you feedback that says \"You need to improve your writing skills,\" you could respond by saying \"I agree, but I think we should focus on improving our research methods instead.\" This response provides constructive criticism without sounding accusatory or dismissive.\\n\\nBlunt feedback can also help to motivate people to take action towards their goals. If someone gives you feedback that says \"You need to work harder on this project,\" you could say \"Thank you for your input, but I think we can']\n"
     ]
    }
   ],
   "source": [
    "prompt_text = \"Question: Is it ever helpful to be blunt with feedback?\\n\\nAnswer:\"\n",
    "encoded = tokenizer(prompt_text, return_tensors=\"pt\")\n",
    "print(dpo_pipeline.generate_text(\n",
    "    input_ids=encoded[\"input_ids\"],\n",
    "    attention_mask=encoded[\"attention_mask\"],\n",
    "    max_new_tokens=150,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d93f524",
   "metadata": {},
   "source": [
    "## APO control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e3048e",
   "metadata": {},
   "source": [
    "APO lives in the same trainer family as DPO and uses the same `DPOTrainer` class (it is activated by simply choosing a different `loss_type`). In contrast to DPO that pushes the policy away from the reference (by a relative KL-scaled margin), APO pushes the policy toward a fixed \"anchor\" score. Generally, APO keeps the policy closer to the reference for the same beta, reducing the risk of over-optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisteer360.algorithms.structural_control.wrappers.trl.apotrainer.control import APO\n",
    "\n",
    "\n",
    "apo = APO(\n",
    "    base_model_name_or_path=MODEL_NAME,\n",
    "    tokenizer_name_or_path=MODEL_NAME,\n",
    "\n",
    "    train_dataset=dpo_train,\n",
    "\n",
    "    output_dir=\"./tmp/apo_lora\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=1e-6,\n",
    "    beta=0.1,\n",
    "    loss_type=\"apo_zero\",     # APO-specific loss\n",
    "    max_prompt_length=512,\n",
    "    max_length=1024,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=99,\n",
    "\n",
    "    use_peft=True,\n",
    "    peft_type=PeftType.LORA,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    adapter_name=\"apo\",\n",
    "\n",
    "    merge_lora_after_train=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d26db93",
   "metadata": {},
   "source": [
    "Steering and inference proceeds as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc765081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
      "Train dataset reference log probs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [01:54<00:00,  2.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 01:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.997600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.986300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.004500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apo_pipeline = SteeringPipeline(\n",
    "    lazy_init=True, \n",
    "    controls=[apo]\n",
    ")\n",
    "apo_pipeline.steer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c62491c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Kindness is a powerful tool that can be used strategically in various situations. It allows us to connect with others, build trust and relationships, and promote positive change. By being kind, we can create a positive impact on the world and help others in need. Additionally, kindness can be used as a way to set an']\n"
     ]
    }
   ],
   "source": [
    "prompt_text = \"Question: Explain why kindness can be strategic.\\n\\nAnswer:\"\n",
    "encoded = tokenizer(prompt_text, return_tensors=\"pt\")\n",
    "print(apo_pipeline.generate_text(\n",
    "    input_ids=encoded[\"input_ids\"],\n",
    "    attention_mask=encoded[\"attention_mask\"],\n",
    "    max_new_tokens=64,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69509bb",
   "metadata": {},
   "source": [
    "## SPPO control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff458b46",
   "metadata": {},
   "source": [
    "SPPO, or self-play preference optimization, can be thought of as extending the offline DPO setting into an on-policy, self-improving loop. The data starts with only a prompt corpus (no human-written answers required). During trainin the policy generates two candidate answers itself. Next, a preference model (or a heuristic judge) ranks the two self-generated candidates. The chosen-rejected is then fed through the DPO-style loss.\n",
    "\n",
    "Because the answers were sampled from the current policy, the optimization is on-policy with the model producing new pairs every few steps so it continuously trains on its own mistakes. A reference model is still necessary to stabilize learning.\n",
    "\n",
    "SPPO is implemented via `SPPOTrainer` and uses the same `DPOTrainerMixin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16889b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /tmp/tmp8q53gdkk\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (80.9.0)\n",
      "Processing /tmp/tmp8q53gdkk/pip-24.0-py3-none-any.whl\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.11/site-packages (24.0)\n",
      "Collecting pip\n",
      "  Using cached pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-25.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llm-blender\n",
      "  Using cached llm_blender-0.0.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.11/site-packages (from llm-blender) (4.57.0)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (from llm-blender) (2.8.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from llm-blender) (2.3.3)\n",
      "Requirement already satisfied: accelerate in ./.venv/lib/python3.11/site-packages (from llm-blender) (1.3.0)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.11/site-packages (from llm-blender) (0.4.5)\n",
      "Collecting dataclasses-json (from llm-blender)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: sentencepiece in ./.venv/lib/python3.11/site-packages (from llm-blender) (0.2.1)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.11/site-packages (from llm-blender) (6.32.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from accelerate->llm-blender) (25.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from accelerate->llm-blender) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.11/site-packages (from accelerate->llm-blender) (6.0.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.venv/lib/python3.11/site-packages (from accelerate->llm-blender) (0.35.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate->llm-blender) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate->llm-blender) (2025.3.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate->llm-blender) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate->llm-blender) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate->llm-blender) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate->llm-blender) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in ./.venv/lib/python3.11/site-packages (from torch->llm-blender) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./.venv/lib/python3.11/site-packages (from triton==3.4.0->torch->llm-blender) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch->llm-blender) (1.3.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llm-blender)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->llm-blender)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->llm-blender)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch->llm-blender) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate->llm-blender) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate->llm-blender) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate->llm-blender) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate->llm-blender) (2025.10.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers->llm-blender) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.11/site-packages (from transformers->llm-blender) (0.22.1)\n",
      "Using cached llm_blender-0.0.2-py3-none-any.whl (92 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, llm-blender\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [llm-blender]\n",
      "\u001b[1A\u001b[2KSuccessfully installed dataclasses-json-0.6.7 llm-blender-0.0.2 marshmallow-3.26.1 mypy-extensions-1.1.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m ensurepip --upgrade\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install llm-blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4075c26c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'hb' from 'aisteer360.algorithms.structural_control.wrappers.trl.sppotrainer.utils_debug' (/dccstor/principled_ai/users/erikmiehling/AISteer360/aisteer360/algorithms/structural_control/wrappers/trl/sppotrainer/utils_debug.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maisteer360\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructural_control\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msppotrainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontrol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SPPO\n\u001b[32m      4\u001b[39m subset = raw_train.select(\u001b[38;5;28mrange\u001b[39m(\u001b[32m200\u001b[39m)).map(\u001b[38;5;28;01mlambda\u001b[39;00m ex: {\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: ex[\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m]}, remove_columns=raw_train.column_names)\n\u001b[32m      6\u001b[39m sppo = SPPO(\n\u001b[32m      7\u001b[39m     base_model_name_or_path=MODEL_NAME,\n\u001b[32m      8\u001b[39m     tokenizer_name_or_path=MODEL_NAME,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     merge_lora_after_train=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     42\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/aisteer360/algorithms/structural_control/wrappers/trl/sppotrainer/__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maisteer360\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructural_control\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msppotrainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01margs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     SPPOArgs,\n\u001b[32m      3\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maisteer360\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructural_control\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msppotrainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontrol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      5\u001b[39m     SPPO,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# __all__ = [\"SPPO\", \"SPPOArgs\"]\u001b[39;00m\n\u001b[32m     10\u001b[39m STEERING_METHOD = {\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mstructural_control\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msppo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontrol\u001b[39m\u001b[33m\"\u001b[39m: SPPO,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m: SPPOArgs,\n\u001b[32m     15\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/aisteer360/algorithms/structural_control/wrappers/trl/sppotrainer/control.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maisteer360\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructural_control\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msppotrainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01margs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SPPOArgs\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maisteer360\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructural_control\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msppotrainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_mixin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SPPOTrainerMixin\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSPPO\u001b[39;00m(SPPOTrainerMixin):\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    SPPO controller.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/aisteer360/algorithms/structural_control/wrappers/trl/sppotrainer/base_mixin.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maisteer360\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructural_control\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_mixin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TRLMixin\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maisteer360\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructural_control\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msppotrainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SPPOTrainer\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maisteer360\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructural_control\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msppotrainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prepare_dataset_from_prompts\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maisteer360\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructural_control\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompt_schema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m standardize_prompt_dataset\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSPPOTrainerMixin\u001b[39;00m(TRLMixin, StructuralControl):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/aisteer360/algorithms/structural_control/wrappers/trl/sppotrainer/utils.py:301\u001b[39m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m raw_dataset\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# def prepare_dataset_from_prompts(\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m#     llm,\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m#     tokenizer,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    299\u001b[39m \n\u001b[32m    300\u001b[39m \u001b[38;5;66;03m# aisteer360/algorithms/structural_control/wrappers/trl/sppotrainer/utils.py\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maisteer360\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructural_control\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msppotrainer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils_debug\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hb, now_s, cuda_stats\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprepare_dataset_from_prompts\u001b[39m(\n\u001b[32m    304\u001b[39m     llm,\n\u001b[32m    305\u001b[39m     tokenizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m     skip_ranking: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    320\u001b[39m ):\n\u001b[32m    321\u001b[39m     debug_dir = debug_dir \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msppo_temp_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/debug\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'hb' from 'aisteer360.algorithms.structural_control.wrappers.trl.sppotrainer.utils_debug' (/dccstor/principled_ai/users/erikmiehling/AISteer360/aisteer360/algorithms/structural_control/wrappers/trl/sppotrainer/utils_debug.py)"
     ]
    }
   ],
   "source": [
    "from aisteer360.algorithms.structural_control.wrappers.trl.sppotrainer.control import SPPO\n",
    "\n",
    "\n",
    "subset = raw_train.select(range(200)).map(lambda ex: {\"prompt\": ex[\"prompt\"]}, remove_columns=raw_train.column_names)\n",
    "\n",
    "sppo = SPPO(\n",
    "    base_model_name_or_path=MODEL_NAME,\n",
    "    tokenizer_name_or_path=MODEL_NAME,\n",
    "    train_dataset=subset,\n",
    "\n",
    "    # SPPO params\n",
    "    start_iteration=1,\n",
    "    end_iteration=1,\n",
    "    max_input_length=1024,\n",
    "    num_prompts=2,  #5,\n",
    "    temp_dir=\"./tmp/sppo_temp\",\n",
    "    gen_max_new_tokens=32,  #100,\n",
    "    ranking_batch_size=8,\n",
    "    limit_num_examples=20,  #50,\n",
    "\n",
    "    # TRL/DPO-compatible params\n",
    "    output_dir=\"./tmp/sppo_final\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-6,\n",
    "    beta=0.001,\n",
    "    loss_type=\"sppo\",\n",
    "    max_prompt_length=512,\n",
    "    max_length=1024,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=123,\n",
    "\n",
    "    # LoRA (optional)\n",
    "    use_peft=True,\n",
    "    peft_type=PeftType.LORA,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    adapter_name=\"sppo\",\n",
    "    merge_lora_after_train=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea3895",
   "metadata": {},
   "source": [
    "We can now construct a steering pipeline, steer it (runs one SPPO iteration, saves checkpoint and final model), and run inference on the steered pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509a74a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m pipeline = SteeringPipeline(\n\u001b[32m      2\u001b[39m     lazy_init=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m      3\u001b[39m     controls=[sppo]\n\u001b[32m      4\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43msteer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/aisteer360/algorithms/core/steering_pipeline.py:155\u001b[39m, in \u001b[36mSteeringPipeline.steer\u001b[39m\u001b[34m(self, **steer_kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m steer_fn = \u001b[38;5;28mgetattr\u001b[39m(control, \u001b[33m\"\u001b[39m\u001b[33msteer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(steer_fn):\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     maybe_new_model = \u001b[43msteer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msteer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_new_model, nn.Module):\n\u001b[32m    157\u001b[39m         \u001b[38;5;28mself\u001b[39m.model = maybe_new_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/aisteer360/algorithms/structural_control/wrappers/trl/sppotrainer/base_mixin.py:99\u001b[39m, in \u001b[36mSPPOTrainerMixin.steer\u001b[39m\u001b[34m(self, model, tokenizer, ref_model, **_)\u001b[39m\n\u001b[32m     96\u001b[39m     iteration_source_dataset = standardize_prompt_dataset(iteration_source_dataset)\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# build processed training data via SPPO’s utility\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m processed_train_dataset = \u001b[43mprepare_dataset_from_prompts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43miteration_source_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43msppo_temp_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43miter_num\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_input_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_prompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgen_max_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen_max_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mranking_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mranking_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimit_num_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlimit_num_examples\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# train one iteration\u001b[39;00m\n\u001b[32m    113\u001b[39m trainer = SPPOTrainer(\n\u001b[32m    114\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    115\u001b[39m     ref_model=\u001b[38;5;28mself\u001b[39m.ref_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m     loss_type=training_config.loss_type,\n\u001b[32m    126\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/aisteer360/algorithms/structural_control/wrappers/trl/sppotrainer/utils.py:248\u001b[39m, in \u001b[36mprepare_dataset_from_prompts\u001b[39m\u001b[34m(llm, tokenizer, data, sppo_temp_dir, iter_num, maxlen, num_prompts, gen_max_new_tokens, ranking_batch_size, limit_num_examples)\u001b[39m\n\u001b[32m    246\u001b[39m llm.eval()\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     generated_ids = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43menc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_max_new_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# short outputs\u001b[39;49;00m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpad_token_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meos_token_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m input_length = enc[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m1\u001b[39m]\n\u001b[32m    259\u001b[39m generated_text = tokenizer.batch_decode(\n\u001b[32m    260\u001b[39m     generated_ids[:, input_length:], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    261\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:2787\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2785\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2786\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2787\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2789\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   2790\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   2791\u001b[39m     outputs,\n\u001b[32m   2792\u001b[39m     model_kwargs,\n\u001b[32m   2793\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2794\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:449\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    430\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    431\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    432\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    434\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    447\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    461\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1066\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1069\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:384\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    397\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    398\u001b[39m     past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    399\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:234\u001b[39m, in \u001b[36mQwen2DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m hidden_states, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:163\u001b[39m, in \u001b[36mQwen2Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[32m    162\u001b[39m     cache_kwargs = {\u001b[33m\"\u001b[39m\u001b[33msin\u001b[39m\u001b[33m\"\u001b[39m: sin, \u001b[33m\"\u001b[39m\u001b[33mcos\u001b[39m\u001b[33m\"\u001b[39m: cos, \u001b[33m\"\u001b[39m\u001b[33mcache_position\u001b[39m\u001b[33m\"\u001b[39m: cache_position}\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     key_states, value_states = \u001b[43mpast_key_values\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m attention_interface: Callable = eager_attention_forward\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation != \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/cache_utils.py:776\u001b[39m, in \u001b[36mCache.update\u001b[39m\u001b[34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m     torch.cuda.default_stream(key_states.device).wait_stream(\u001b[38;5;28mself\u001b[39m.prefetch_stream)\n\u001b[32m    774\u001b[39m     \u001b[38;5;28mself\u001b[39m.prefetch(layer_idx + \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.only_non_sliding)\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m keys, values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.offloading:\n\u001b[32m    779\u001b[39m     \u001b[38;5;28mself\u001b[39m.offload(layer_idx, \u001b[38;5;28mself\u001b[39m.only_non_sliding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/transformers/cache_utils.py:119\u001b[39m, in \u001b[36mDynamicLayer.update\u001b[39m\u001b[34m(self, key_states, value_states, cache_kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_initialized:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mself\u001b[39m.lazy_initialization(key_states)\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28mself\u001b[39m.keys = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;28mself\u001b[39m.values = torch.cat([\u001b[38;5;28mself\u001b[39m.values, value_states], dim=-\u001b[32m2\u001b[39m)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keys, \u001b[38;5;28mself\u001b[39m.values\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "pipeline = SteeringPipeline(\n",
    "    lazy_init=True, \n",
    "    controls=[sppo]\n",
    ")\n",
    "pipeline.steer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a short, constructive response to: 'My partner always interrupts me.'\"\n",
    "enc = tokenizer(prompt, return_tensors=\"pt\")\n",
    "print(pipeline.generate_text(\n",
    "    input_ids=enc[\"input_ids\"],\n",
    "    attention_mask=enc[\"attention_mask\"],\n",
    "    max_new_tokens=64,\n",
    "    do_sample=False,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edef0904",
   "metadata": {},
   "source": [
    "## Full-parameter SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee8cd3f",
   "metadata": {},
   "source": [
    "Lastly, to run a full-weight fine-tune set `use_peft=False`, drop the LoRA arguments, and usually shrink the batch size (because every parameter now receives gradients). \n",
    "\n",
    "Note: Full fine-tuning can be 10-20 times more memory-intensive than LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d5972",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sft = SFT(\n",
    "    base_model_name_or_path=MODEL_NAME,\n",
    "    tokenizer_name_or_path=MODEL_NAME,\n",
    "    train_dataset=sft_train,\n",
    "    use_peft=False,               # full FT\n",
    "    output_dir=\"./tmp/sft_full\",\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-6,\n",
    "    report_to=\"none\",\n",
    "    seed=7,\n",
    ")\n",
    "full_pipeline = SteeringPipeline(\n",
    "    lazy_init=True, \n",
    "    controls=[full_sft]\n",
    ")\n",
    "full_pipeline.steer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba56bdf",
   "metadata": {},
   "source": [
    "The wrapper also provides functionality for resuming training if interrupted (via TRL's `resume_from_checkpoint`) by providing either the directory path of the checkpoint name in `output_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed78815",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_sft = SFT(\n",
    "    base_model_name_or_path=MODEL_NAME,\n",
    "    tokenizer_name_or_path=MODEL_NAME,\n",
    "    train_dataset=sft_train,\n",
    "    output_dir=\"./tmp/sft_lora\",\n",
    "    resume_from_checkpoint=\"./tmp/sft_lora/checkpoint-1000\",\n",
    "    use_peft=True,\n",
    "    adapter_name=\"sft\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "resume_pipeline = SteeringPipeline(\n",
    "    lazy_init=True, \n",
    "    controls=[resume_sft]\n",
    ")\n",
    "resume_pipeline.steer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e20bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
